# Proyecto Did谩ctico de Modelos Predictivos para IA

隆Bienvenido/a! Este repositorio est谩 dise帽ado como un recurso educativo para estudiantes universitarios de especializaci贸n en Inteligencia Artificial que deseen aprender sobre la implementaci贸n pr谩ctica de modelos predictivos.

##  Objetivo del Proyecto

El objetivo principal es desmitificar los modelos de Machine Learning y la ciencia de datos a trav茅s de ejemplos pr谩cticos, claros y extensamente comentados. Cada script en este repositorio es una gu铆a paso a paso que no solo muestra *c贸mo* implementar un modelo, sino tambi茅n *por qu茅* funciona y *qu茅* significan sus resultados.

La filosof铆a es "aprender haciendo", enfoc谩ndonos en:
- **C贸digo Funcional:** Scripts completos que puedes ejecutar desde el principio hasta el fin.
- **Explicaciones Conceptuales:** Comentarios detallados que explican la teor铆a matem谩tica y estad铆stica de una manera intuitiva.
- **Aplicaci贸n Real:** Uso de datasets para resolver problemas concretos, como la predicci贸n de series temporales.

##  Estructura del Repositorio

Cada modelo predictivo se encuentra en su propio archivo de Python (`.py`). Los scripts est谩n divididos en fases l贸gicas para facilitar el aprendizaje:

1.  **Fase 0: Preparaci贸n:** Importaci贸n de las librer铆as necesarias.
2.  **Fase 1: Carga y Preparaci贸n de Datos:** El paso cr铆tico de limpiar y transformar los datos al formato que el modelo requiere.
3.  **Fase 2: Entendiendo el Modelo:** Una explicaci贸n conceptual y matem谩tica (simplificada) de c贸mo funciona el modelo.
4.  **Fase 3: Entrenamiento:** El proceso de "ense帽ar" al modelo usando los datos hist贸ricos.
5.  **Fase 4: Predicci贸n/Inferencia:** Usar el modelo entrenado para hacer predicciones sobre datos nuevos o futuros.
6.  **Fase 5: Visualizaci贸n y Evaluaci贸n:** Interpretar los resultados a trav茅s de gr谩ficos y m茅tricas.

---

##  Modelos Incluidos

A continuaci贸n se presenta un resumen de los modelos disponibles en este proyecto.

### 1. Prophet de Meta (Series Temporales)

*   **Archivo:** `prophet-main.py` | **Tipo:** Series Temporales
*   **Tipo:** Modelo de Series Temporales.

#### 驴Qu茅 es Prophet?

Prophet es un modelo desarrollado por Meta (Facebook) espec铆ficamente dise帽ado para predecir datos de series temporales. Es especialmente potente cuando los datos tienen **patrones estacionales fuertes** (por ejemplo, semanales, anuales) y efectos de d铆as festivos. Su popularidad radica en que es f谩cil de usar, robusto ante datos faltantes y at铆picos, y altamente interpretable.

#### 驴C贸mo funciona?

Prophet utiliza un **modelo aditivo**, lo que significa que descompone la serie temporal en varios componentes y los suma para generar la predicci贸n final. La f贸rmula principal es:

`y(t) = g(t) + s(t) + h(t) + e(t)`

Donde:
- **`y(t)`**: Es la predicci贸n final en el tiempo `t`.
- **`g(t)` - Tendencia (Trend)**: Modela el cambio no peri贸dico a lo largo del tiempo. Es la direcci贸n general de los datos (驴crecen o decrecen a largo plazo?).
- **`s(t)` - Estacionalidad (Seasonality)**: Captura los patrones peri贸dicos. Por ejemplo, el aumento de ventas cada fin de semana (estacionalidad semanal) o durante el verano (estacionalidad anual). Prophet utiliza series de Fourier para modelar estos ciclos.
- **`h(t)` - Festivos (Holidays)**: Modela el efecto de eventos irregulares pero predecibles, como Navidad, el Buen Fin o un feriado nacional, que impactan el comportamiento normal de los datos.
- **`e(t)` - Error**: Representa el ruido o las variaciones aleatorias que el modelo no puede explicar con los otros componentes.

La gran ventaja de este enfoque es que podemos visualizar cada componente por separado, lo que nos permite entender *por qu茅* el modelo hace una determinada predicci贸n.

#### Aplicaci贸n en el Ejemplo

En el script `prophet-main.py`, utilizamos este modelo para un caso pr谩ctico de negocio:

1.  **Datos:** Se utiliza un archivo CSV con transacciones de ventas, que incluye la fecha y el monto de cada transacci贸n.
2.  **Objetivo:** Predecir el **monto total de transacciones por d铆a** para los pr贸ximos 365 d铆as.
3.  **Proceso:**
    - Los datos de transacciones individuales se agrupan para obtener una suma total por d铆a, creando as铆 una serie temporal diaria.
    - Se prepara el DataFrame para que tenga las columnas requeridas por Prophet: `ds` (fecha) y `y` (valor a predecir).
    - Se entrena el modelo Prophet con los datos hist贸ricos.
    - Se genera un pron贸stico a un a帽o.
    - Finalmente, se visualiza tanto la predicci贸n completa (con sus intervalos de incertidumbre) como los componentes individuales (tendencia, estacionalidad semanal y anual) que el modelo ha aprendido.

Este ejemplo te permitir谩 entender c贸mo pasar de datos brutos a un pron贸stico accionable y, lo m谩s importante, c贸mo interpretar los patrones que el modelo descubre.

### 2. Regresi贸n Log铆stica

*   **Archivo:** `regresion-logistica.py` | **Tipo:** Clasificaci贸n Binaria

#### 驴Qu茅 es la Regresi贸n Log铆stica?

Es uno de los modelos fundamentales para problemas de **clasificaci贸n binaria** (predecir un resultado con solo dos opciones, como S铆/No, 1/0, Aceptada/Rechazada). A pesar de su nombre, se usa para clasificaci贸n, no para regresi贸n. Es r谩pido, eficiente y, lo m谩s importante, sus resultados son muy f谩ciles de interpretar.

#### 驴C贸mo funciona?

La Regresi贸n Log铆stica calcula la **probabilidad** de que una observaci贸n pertenezca a una clase. Utiliza la **funci贸n sigmoide**, una curva en forma de "S" que transforma cualquier valor num茅rico en una probabilidad entre 0 y 1.

El modelo aprende un "coeficiente" (o peso) para cada variable de entrada.
- Un **coeficiente positivo** significa que al aumentar esa variable, aumenta la probabilidad del resultado "1" (ej. 'Aceptada').
- Un **coeficiente negativo** significa que al aumentar esa variable, disminuye la probabilidad del resultado "1".

Si la probabilidad calculada es mayor que un umbral (normalmente 0.5), el modelo predice la clase "1"; de lo contrario, predice "0".

#### Aplicaci贸n en el Ejemplo

En `regresion-logistica.py`, el modelo predice si una transacci贸n ser谩 **'Aceptada' (1) o 'Rechazada' (0)**. El script te gu铆a a trav茅s de:
1.  **Preprocesamiento:** Convertir variables de texto (como el pa铆s) en un formato num茅rico que el modelo entienda (usando *One-Hot Encoding*) y escalar las variables num茅ricas.
2.  **Entrenamiento:** El modelo aprende los coeficientes para variables como 'Monto de transacci贸n', 'Puntuacion_Crediticia', etc.
3.  **Interpretaci贸n:** Se analizan los coeficientes para entender qu茅 factores tienen el mayor impacto positivo o negativo en la probabilidad de que una transacci贸n sea aceptada.

### 3. K-Nearest Neighbors (kNN)

*   **Archivo:** `k-nearest.py` | **Tipo:** Clasificaci贸n

#### 驴Qu茅 es kNN?

Es un algoritmo de "aprendizaje perezoso" o basado en instancias. Su l贸gica es incre铆blemente intuitiva: "dime qui茅nes son tus vecinos y te dir茅 qui茅n eres". Para clasificar un nuevo dato, simplemente mira a los 'k' datos m谩s cercanos (vecinos) en el conjunto de entrenamiento y le asigna la clase m谩s com煤n entre ellos.

#### 驴C贸mo funciona?

1.  **Almacenamiento:** El "entrenamiento" de kNN consiste 煤nicamente en memorizar todos los datos de entrenamiento y sus etiquetas.
2.  **C谩lculo de Distancia:** Cuando llega un nuevo punto, calcula la distancia (generalmente la distancia euclidiana) entre este nuevo punto y **todos** los puntos del conjunto de entrenamiento.
3.  **Votaci贸n:** Identifica los 'k' puntos m谩s cercanos (los vecinos con la menor distancia).
4.  **Clasificaci贸n:** La clase que m谩s se repite entre esos 'k' vecinos es la predicci贸n final para el nuevo punto.

**隆Importante!** kNN es muy sensible a la escala de las variables. Por eso, es crucial **estandarizar** los datos antes de entrenar el modelo, como se muestra en el script.

#### Aplicaci贸n en el Ejemplo

En `k-nearest.py`, el modelo clasifica una transacci贸n como **'Aceptada' o 'Rechazada'**. El script se enfoca en:
1.  **Estandarizaci贸n:** Demostrar por qu茅 es vital escalar caracter铆sticas como 'Monto de transacci贸n' y 'Pa铆s' para que ambas tengan la misma importancia en el c谩lculo de la distancia.
2.  **Visualizaci贸n:** Se incluye un gr谩fico que ilustra visualmente el concepto: muestra un nuevo punto, identifica a sus 'k' vecinos m谩s cercanos y c贸mo estos "votan" para decidir su clase.

### 4. Random Forest (Bosque Aleatorio)

*   **Archivo:** `random-forest.py` | **Tipo:** Clasificaci贸n (y Regresi贸n)

#### 驴Qu茅 es Random Forest?

Es un modelo de "aprendizaje en conjunto" (ensemble) que combina las predicciones de muchos **谩rboles de decisi贸n** individuales para obtener una predicci贸n final m谩s robusta y precisa. La analog铆a es como consultar a un comit茅 de expertos en lugar de a uno solo: la decisi贸n del grupo suele ser mejor que la de cualquier individuo.

#### 驴C贸mo funciona?

1.  **Bootstrap Aggregating (Bagging):** Crea m煤ltiples subconjuntos de datos de entrenamiento tomando muestras aleatorias con reemplazo.
2.  **Construcci贸n de rboles:** Entrena un 谩rbol de decisi贸n en cada uno de estos subconjuntos. Para cada divisi贸n en el 谩rbol, solo considera un subconjunto aleatorio de las caracter铆sticas disponibles. Esta doble aleatoriedad (en datos y en caracter铆sticas) es lo que hace que los 谩rboles sean diferentes entre s铆 y reduce el sobreajuste.
3.  **Votaci贸n:** Para una nueva predicci贸n, cada 谩rbol en el bosque emite su "voto". La clase que recibe la mayor铆a de los votos es la predicci贸n final del bosque.

#### Aplicaci贸n en el Ejemplo

En `random-forest.py`, se utiliza un conjunto de datos sint茅ticos para predecir si un cliente realizar谩 una **'Compra' (1) o 'No Compra' (0)**. El script muestra c贸mo:
1.  Generar datos de ejemplo realistas.
2.  Entrenar un bosque con 100 谩rboles (`n_estimators=100`).
3.  Evaluar el modelo usando una matriz de confusi贸n para entender los tipos de errores (Falsos Positivos y Falsos Negativos).

### 5. Modelos de Gradient Boosting (Gradient Boosting, XGBoost, LightGBM)

Estos tres modelos pertenecen a la misma familia de algoritmos de "boosting", que son de los m谩s potentes y populares en competencias de Machine Learning. La idea central es construir modelos de forma secuencial, donde cada nuevo modelo se enfoca en corregir los errores del anterior.

#### 驴C贸mo funcionan?

Imagina un equipo de especialistas construyendo algo:
1.  El primer modelo (un 谩rbol simple) hace una predicci贸n inicial, cometiendo errores evidentes.
2.  El segundo modelo no predice el objetivo original, sino que se entrena para **predecir los errores** (residuos) del primer modelo.
3.  La predicci贸n del segundo modelo se suma a la del primero, corrigiendo parte del error.
4.  Un tercer modelo se entrena para corregir los errores restantes, y as铆 sucesivamente.

El resultado es un conjunto de modelos que, en equipo, logran una predicci贸n extremadamente precisa.

---

#### 5.1. Gradient Boosting Classifier

*   **Archivo:** `Gradient-boosting-classifier.py` | **Tipo:** Clasificaci贸n
*   **Descripci贸n:** Es la implementaci贸n fundamental de este concepto disponible en `scikit-learn`. Es robusta y una excelente base para entender el boosting. En el script, se usa para predecir si una transacci贸n es **'Aceptada' o 'Rechazada'** y se muestra c贸mo analizar la "importancia de las caracter铆sticas" para ver qu茅 variables influyen m谩s en la decisi贸n.

---

#### 5.2. XGBoost (Extreme Gradient Boosting)

*   **Archivo:** `XGBoost.py` | **Tipo:** Clasificaci贸n y Regresi贸n
*   **Descripci贸n:** XGBoost es una implementaci贸n optimizada y de alto rendimiento del Gradient Boosting. Es famoso por su velocidad y precisi贸n. Incluye mejoras como la regularizaci贸n (para evitar el sobreajuste) y la capacidad de manejar valores faltantes de forma nativa.
*   **Aplicaci贸n en el Ejemplo:** El script `XGBoost.py` es 煤nico porque aborda **dos tareas**:
    1.  **Clasificaci贸n:** Predecir si una transacci贸n es **'Aceptada' o 'Rechazada'**.
    2.  **Regresi贸n:** Predecir el **'Monto de la transacci贸n'** (un valor num茅rico continuo).
    Esto te permite comparar c贸mo se aplica el mismo algoritmo a dos tipos de problemas diferentes y c贸mo se eval煤an (Accuracy para clasificaci贸n, MAE/RMSE para regresi贸n).

---

#### 5.3. LightGBM (Light Gradient Boosting Machine)

*   **Archivo:** `LightGBM.py` | **Tipo:** Clasificaci贸n
*   **Descripci贸n:** Es otra implementaci贸n de alto rendimiento, desarrollada por Microsoft. Su principal ventaja es la **velocidad y eficiencia con grandes conjuntos de datos**. A diferencia de otros 谩rboles que crecen nivel por nivel (horizontalmente), LightGBM crece hoja por hoja (verticalmente), enfoc谩ndose en las hojas donde puede reducir m谩s el error.
*   **Aplicaci贸n en el Ejemplo:** En `LightGBM.py`, se usa para un problema de clasificaci贸n de **'Aceptada'/'Rechazada'**. El script destaca c贸mo LightGBM puede manejar variables categ贸ricas de forma nativa y eficiente, y c贸mo visualizar la importancia de las caracter铆sticas para interpretar el modelo.

---

##  驴C贸mo empezar?

1.  Clona este repositorio en tu m谩quina local.
2.  Aseg煤rate de tener Python y crea un entorno virtual para instalar las librer铆as necesarias. Puedes instalarlas todas con pip:
    ```bash
    pip install pandas prophet matplotlib scikit-learn numpy seaborn lightgbm xgboost
    ```
3.  Abre el script del modelo que te interese (ej. `random-forest.py`) en tu editor de c贸digo o IDE favorito.
4.  Lee los comentarios y ejecuta el script celda por celda o todo de una vez para ver los resultados.
5.  隆Experimenta! Cambia los par谩metros, usa tus propios datos o intenta a帽adir nuevas funcionalidades como los d铆as festivos (`add_country_holidays`).

隆Feliz aprendizaje!
